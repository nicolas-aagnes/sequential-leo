{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython import display\n",
    "\n",
    "from datasets import Dataset2D\n",
    "from models.leo import LSTMTheta\n",
    "from models.mlp import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 2]) torch.Size([5, 4, 2]) torch.Size([15, 10, 2]) torch.Size([15, 4, 2])\n",
      "torch.Size([5, 10, 2]) torch.Size([5, 4, 2]) torch.Size([15, 10, 2]) torch.Size([15, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "num_support, num_query, num_frames, horizon = 5, 15, 10, 4\n",
    "\n",
    "batch_size = 32\n",
    "dataset_train = Dataset2D(num_support, num_query, num_frames=10, horizon=4, return_amplitude_and_phase=False)\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "for task_batch in dataloader_train:\n",
    "    for x_support, y_support, x_query, y_query in zip(*task_batch):\n",
    "        x_support, y_support, x_query, y_query = x_support.float(), y_support.float(), x_query.float(), y_query.float()\n",
    "        print(x_support.shape, y_support.shape, x_query.shape, y_query.shape) \n",
    "        break # This otherwise gets printed batch_size times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 16])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_support has shape (num_support, num_frames, 2), assuming we're in a for loop over the bathes.\n",
    "input_size = 2 # 2 for 2D dataset, this will be 17 * 3 for the human36 dataset.\n",
    "encoder_hidden_size = 16\n",
    "\n",
    "encoder = torch.nn.LSTM(input_size=input_size, hidden_size=encoder_hidden_size, num_layers=1, batch_first=True)\n",
    "\n",
    "encoder_output, _ = encoder(x_support)\n",
    "encoder_output = encoder_output[:, -1]\n",
    "encoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output from the encoder has shape (num_support, num_frames, encoder_hidden_size)\n",
    "relation_input = encoder_output.ravel()\n",
    "print(relation_input.shape) # Equal to num_support * encoder_hidden_size\n",
    "\n",
    "z_dim = 16\n",
    "\n",
    "relation_net = MLP(num_support * encoder_hidden_size, 32, z_dim * 2)\n",
    "relation_out = relation_net(relation_input).view(2, -1)\n",
    "relation_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_theta_hidden_size = 128\n",
    "theta_size = f_theta_hidden_size * input_size\n",
    "\n",
    "def sample_from_normal(mean, variance):\n",
    "        return mean + torch.sqrt(torch.exp(variance)) * torch.randn(*mean.shape) # TODO: Check the exp function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = sample_from_normal(relation_out[0], relation_out[1]) # shape = z_dim\n",
    "assert z.size() == (z_dim, ), z.size()\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = MLP(z_dim, 32, theta_size * 2)\n",
    "\n",
    "theta_params = decoder(z).view(2, -1)\n",
    "theta_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 2])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = sample_from_normal(theta_params[0], theta_params[1]) # shape = z_dim\n",
    "assert theta.size() == (theta_size, )\n",
    "print(theta.shape)\n",
    "theta = theta.view(f_theta_hidden_size, input_size)\n",
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMTheta(\n",
       "   (lstm_cell): LSTMCell(2, 128)\n",
       " ),\n",
       " torch.Size([5, 10, 2]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_theta = LSTMTheta(input_size, f_theta_hidden_size, horizon)\n",
    "f_theta, x_support.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 2])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = f_theta((x_support, theta))\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "f_theta_hidden_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEO Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from models.leo import LEO\n",
    "\n",
    "@dataclass\n",
    "class LEOConfig:\n",
    "    num_support: int\n",
    "    num_timesteps_pred: int\n",
    "    input_size: int\n",
    "    encoder_hidden_size: int\n",
    "    relation_net_hidden_size: int\n",
    "    z_dim: int\n",
    "    decoder_hidden_size: int\n",
    "    f_theta_hidden_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_support, num_query, num_timesteps, num_timesteps_pred, batch_size = 5, 15, 10, 4, 32\n",
    "\n",
    "dataset_train = Dataset2D(num_support, num_query, num_timesteps, num_timesteps_pred, return_amplitude_and_phase=False)\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LEOConfig(\n",
    "    num_support=num_support,\n",
    "    num_timesteps_pred=num_timesteps_pred,\n",
    "    input_size=2,\n",
    "    encoder_hidden_size=16,\n",
    "    relation_net_hidden_size=16,\n",
    "    z_dim=16,\n",
    "    decoder_hidden_size=32,\n",
    "    f_theta_hidden_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 2]) torch.Size([5, 4, 2]) torch.Size([15, 10, 2]) torch.Size([15, 4, 2])\n",
      "torch.Size([5, 10, 2]) torch.Size([5, 4, 2]) torch.Size([15, 10, 2]) torch.Size([15, 4, 2])\n",
      "torch.Size([5, 10, 2]) torch.Size([5, 4, 2]) torch.Size([15, 10, 2]) torch.Size([15, 4, 2])\n",
      "torch.Size([5, 10, 2]) torch.Size([5, 4, 2]) torch.Size([15, 10, 2]) torch.Size([15, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "for task_batch in dataloader_train:\n",
    "    for x_support, y_support, x_query, y_query in zip(*task_batch):\n",
    "        x_support, y_support, x_query, y_query = x_support.float(), y_support.float(), x_query.float(), y_query.float()\n",
    "        print(x_support.shape, y_support.shape, x_query.shape, y_query.shape) \n",
    "        model.train\n",
    "        break # This otherwise gets printed batch_size times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training.\n",
      "Iteration 0, 32 tasks: 7.710\n",
      "Iteration 1, 64 tasks: 5.320\n",
      "Iteration 2, 96 tasks: 5.334\n",
      "Iteration 3, 100 tasks: 2.738\n"
     ]
    }
   ],
   "source": [
    "model = LEO(num_inner_steps=1, inner_lr=0.01, learn_inner_lr=False, outer_lr=0.01, log_dir=\"\", config=config)\n",
    "model.train(dataloader_train, dataloader_train, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5526cef0f2beafd42cdc7fc832a51a04d29fb96c99f27e2398157171bc8dd373"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
